# =============================================================================
# 0. KÃœTÃœPHANE VE AYARLAR (IMPORTS)
# =============================================================================

# 1. Standart Python ve UyarÄ±lar
import warnings
# Gereksiz uyarÄ±larÄ± kapat (Temiz Ã§Ä±ktÄ± iÃ§in)
warnings.filterwarnings("ignore")
from sklearn.exceptions import ConvergenceWarning
warnings.filterwarnings("ignore", category=ConvergenceWarning)

# 2. Veri Ä°ÅŸleme ve Matematik (Data Manipulation)
import numpy as np
import pandas as pd
import holidays

# 3. GÃ¶rselleÅŸtirme (Visualization)
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import seaborn as sns

# 4. Ä°statistik ve Zaman Serisi Analizi (Statistics)
import scipy.stats as stats
from scipy.stats import norm
import statsmodels.api as sm
from statsmodels.tsa.stattools import adfuller
from statsmodels.stats.stattools import durbin_watson  # Durbin-Watson eklendi
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

# 5. DÄ±ÅŸ Veri KaynaklarÄ± (External Data)
import yfinance as yf

# 6. Makine Ã–ÄŸrenmesi ve Metrikler (Machine Learning)
import xgboost as xgb
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV
from sklearn.metrics import mean_squared_error, mean_absolute_error

# 7. AÃ§Ä±klanabilir Yapay Zeka (XAI)
import shap

# GÃ¶rselleÅŸtirme AyarlarÄ± (Opsiyonel ama Ã¶nerilir)
sns.set(style="whitegrid")
plt.rcParams["figure.figsize"] = (12, 6)

print("âœ… TÃ¼m kÃ¼tÃ¼phaneler baÅŸarÄ±yla yÃ¼klendi ve ayarlandÄ±.")


# ---------------------------
# AYARLAR
# ---------------------------

warnings.filterwarnings("ignore")
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.simplefilter(action="ignore", category=ConvergenceWarning)
pd.set_option('display.max_columns', None)
pd.set_option('display.width', 500)
pd.set_option('display.float_format', lambda x: '%.3f' % x)

# ---------------------------
# VERÄ° OKUMA
# ---------------------------
"""df_final = pd.read_csv("data_s/data_set.csv")"""
df_final = pd.read_excel("data_s/data_set_ex.xlsx")
df_final_c = df_final.copy()
# ---------------------------
# DEÄÄ°ÅKEN TÄ°PÄ° DÃœZELTME
# --------------------------

def clean_currency(x):
    if isinstance(x, str):
        x = x.replace('.', '').replace(',', '.')
    return float(x)

object_to_float = [col for col in df_final.columns if col not in ['Tarih', 'Saat', 'Zaman']]
for col in object_to_float:
    df_final[col] = df_final[col].apply(clean_currency)

df_final['Tarih'] = pd.to_datetime(df_final['Tarih'], format='%d.%m.%Y').dt.normalize()
df_final['Zaman'] = pd.to_datetime(df_final['Tarih'].astype(str) + ' ' + df_final['Saat'].astype(str))



df_final['Tarih'] = pd.to_datetime(df_final['Tarih'], format='%d.%m.%Y').dt.normalize()
df_final['Saat'] = pd.to_datetime(df_final['Saat']).dt.time
df_final.head()
df_final.info()


# ---------------------------
# DOLAR VE BOTAÅ EKLEME
# ---------------------------

# ---------------------------
# DOLAR KURU (YAHOO)
# ---------------------------
start_date = df_final['Tarih'].min()
end_date = df_final['Tarih'].max()
usd_data = yf.download('TRY=X', start=start_date, end=end_date + pd.Timedelta(days=5))
usd_data = usd_data[['Close']].reset_index()
usd_data.columns = ['Tarih', 'Dolar_Kuru']
usd_data['Tarih'] = pd.to_datetime(usd_data['Tarih']).dt.normalize()
usd_data['Tarih'] = usd_data['Tarih'].dt.tz_localize(None)
# Eksik gÃ¼nleri doldur
all_dates = pd.DataFrame({'Tarih': pd.date_range(start=start_date, end=end_date, freq='D')})
all_dates['Tarih'] = all_dates['Tarih'].dt.normalize()
usd_data = pd.merge(all_dates, usd_data, on='Tarih', how='left')
usd_data['Dolar_Kuru'] = usd_data['Dolar_Kuru'].ffill().bfill()
# Ana veriye ekle
df_final = pd.merge(df_final, usd_data, on='Tarih', how='left')

# ---------------------------
# BOTAÅ DOÄALGAZ VERÄ°SÄ°
# ---------------------------
#
df_final['dogalgaz_fiyatlari_Mwh'] = 1692.00
df_final.loc[df_final['Tarih'] >= '2024-07-02', 'dogalgaz_fiyatlari_Mwh'] = 1127.82
df_final.loc[df_final['Tarih'] >= '2025-07-01', 'dogalgaz_fiyatlari_Mwh'] = 1409.77

df_final.describe().T
#////////////////////////////////////////////////////////////////////////////////////









# =============================================================================
#   ADIM 0                --EDA--
# =============================================================================
# =============================================================================
# YARDIMCI FONKSÄ°YONLAR (ALT PARÃ‡ALAR)
# =============================================================================

def data_summary(dataframe, head=5):
    """Veri setinin genel Ã¶zetini basar."""
    print("\n##################### Shape #####################")
    print(dataframe.shape)
    print("##################### Type #####################")
    print(dataframe.dtypes)
    print("##################### Head #####################")
    print(dataframe.head(head))
    print("##################### Tail #####################")
    print(dataframe.tail(head))
    print("##################### NA Check #####################")
    print(dataframe.isnull().sum())
    print("##################### Quantiles #####################")
    print(dataframe.describe([0.05, 0.50, 0.95, 0.99]).T)


def clean_negative_values(dataframe, col_name='GÃ¼neÅŸ'):
    """Negatif deÄŸerleri temizler ve 0'a eÅŸitler."""
    if col_name in dataframe.columns:
        print(f"\n--- '{col_name}' DeÄŸiÅŸkeni TemizliÄŸi ---")
        print(f"Negatif SayÄ±sÄ±: {(dataframe[col_name] < 0).sum()}")
        dataframe[col_name] = dataframe[col_name].clip(lower=0)
        print(f"DÃ¼zeltme SonrasÄ± Negatif SayÄ±sÄ±: {(dataframe[col_name] < 0).sum()}")
    return dataframe


def degisken_analiz(dataframe, cat_th=2, car_th=20):
    """Kategorik ve Numerik deÄŸiÅŸkenleri ayÄ±rÄ±r."""
    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == "O"]
    num_but_cat = [col for col in dataframe.columns if
                   dataframe[col].nunique() < cat_th and dataframe[col].dtypes != "O"]
    cat_but_car = [col for col in dataframe.columns if
                   dataframe[col].nunique() > car_th and dataframe[col].dtypes == "O"]

    cat_cols = cat_cols + num_but_cat
    cat_cols = [col for col in cat_cols if col not in cat_but_car]

    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != "O"]
    num_cols = [col for col in num_cols if col not in num_but_cat]

    print(f"\n--- DeÄŸiÅŸken Analizi ---")
    print(f"GÃ¶zlem SayÄ±sÄ±: {dataframe.shape[0]}")
    print(f"DeÄŸiÅŸken SayÄ±sÄ±: {dataframe.shape[1]}")
    print(f'Kategorik DeÄŸiÅŸkenler: {len(cat_cols)}')
    print(f'Numerik DeÄŸiÅŸkenler: {len(num_cols)}')
    print(f'Kardinalitesi YÃ¼ksek Kategorikler: {len(cat_but_car)}')
    print(f'Numerik GÃ¶rÃ¼nÃ¼mlÃ¼ Kategorikler: {len(num_but_cat)}')

    return cat_cols, num_cols, cat_but_car


def numeric_summary(dataframe, numerical_col, plot=False):
    """Numerik deÄŸiÅŸkenlerin istatistiklerini ve histogramÄ±nÄ± Ã§izer."""
    quantiles = [0.05, 0.25, 0.50,0.75,0.95]
    print(f"\n###### {numerical_col} Ã–zeti ######")
    print(dataframe[numerical_col].describe(quantiles).T)
    if plot:
        dataframe[numerical_col].hist(bins=20)
        plt.xlabel(numerical_col)
        plt.title(numerical_col)
        plt.show()


def target_summary_with_numeric(dataframe, target, numerical_col):
    """Hedef deÄŸiÅŸkene gÃ¶re numerik deÄŸiÅŸkenlerin ortalamasÄ±nÄ± alÄ±r."""
    print(f"\n--- {target} KÄ±rÄ±lÄ±mÄ±nda {numerical_col} OrtalamasÄ± ---")
    print(dataframe.groupby(target).agg({numerical_col: "mean"}))


def plot_correlation_matrix(dataframe, num_cols):
    """Korelasyon matrisini Ã§izer."""
    print("\n--- Korelasyon Matrisi Ã‡iziliyor ---")
    if len(num_cols) > 1:
        corr = dataframe[num_cols].corr()
        f, ax = plt.subplots(figsize=[18, 13])
        sns.heatmap(corr, annot=True, fmt=".2f", ax=ax, cmap="magma")
        ax.set_title("Correlation Matrix", fontsize=20)
        plt.show(block=True)
    else:
        print("Yeterli sayÄ±sal deÄŸiÅŸken yok.")


def check_physical_integrity(df):
    """Fiziksel mantÄ±k kontrollerini yapar."""
    print("\nğŸ•µï¸â€â™‚ï¸ Fiziksel TutarlÄ±lÄ±k KontrolÃ¼ YapÄ±lÄ±yor...")

    # 1. Negatif Ãœretim KontrolÃ¼
    prod_cols = ['RÃ¼zgar', 'GÃ¼neÅŸ', 'DoÄŸalgaz', 'BarajlÄ±', 'Linyit']
    existing_cols = [c for c in prod_cols if c in df.columns]

    for col in existing_cols:
        negatives = df[df[col] < 0]
        if len(negatives) > 0:
            print(f"âš ï¸ UYARI: {col} sÃ¼tununda {len(negatives)} adet negatif deÄŸer var! 0'a eÅŸitleniyor.")
            df.loc[df[col] < 0, col] = 0
        else:
            print(f"âœ… {col}: Temiz (Negatif yok).")

    # 2. PTF KontrolÃ¼
    MAX_PRICE_LIMIT = 6000
    MIN_PRICE_LIMIT = 0
    if 'PTF (TL/MWH)' in df.columns:
        errors = df[(df['PTF (TL/MWH)'] > MAX_PRICE_LIMIT) | (df['PTF (TL/MWH)'] < MIN_PRICE_LIMIT)]
        if len(errors) > 0:
            print(f"ğŸš¨ KRÄ°TÄ°K: PTF sÃ¼tununda {len(errors)} adet mantÄ±ksÄ±z deÄŸer var!")
        else:
            print("âœ… PTF: MantÄ±ksÄ±z uÃ§ deÄŸer (Error) gÃ¶rÃ¼nmÃ¼yor.")

    return df


def plot_all_boxplots(df):
    """GruplandÄ±rÄ±lmÄ±ÅŸ BoxplotlarÄ± Ã§izer."""
    print("\n--- Boxplot Analizi Ã‡iziliyor ---")
    sns.set_theme(style="whitegrid")

    # GruplarÄ± mevcut sÃ¼tunlara gÃ¶re filtrele
    price_cols = [c for c in ['PTF (TL/MWH)', 'Dolar_Kuru', 'dogalgaz_fiyatlari_Mwh'] if c in df.columns]
    large_scale_cols = [c for c in ['YÃ¼k Tahmin PlanÄ± (MWh)', 'DoÄŸalgaz', 'BarajlÄ±', 'Ä°thal KÃ¶mÃ¼r'] if c in df.columns]
    renewable_cols = [c for c in ['RÃ¼zgar', 'GÃ¼neÅŸ', 'Akarsu', 'Linyit', 'Jeotermal', 'BiyokÃ¼tle', 'Fuel Oil'] if
                      c in df.columns]

    fig, axes = plt.subplots(3, 1, figsize=(14, 18))

    if price_cols:
        sns.boxplot(data=df[price_cols], ax=axes[0], palette="Set2")
        axes[0].set_title('Grup 1: Fiyat BazlÄ± DeÄŸiÅŸkenler')

    if large_scale_cols:
        sns.boxplot(data=df[large_scale_cols], ax=axes[1], palette="Set1")
        axes[1].set_title('Grup 2: YÃ¼k ve BÃ¼yÃ¼k Ã–lÃ§ekli Ãœretimler')

    if renewable_cols:
        sns.boxplot(data=df[renewable_cols], ax=axes[2], palette="Pastel1")
        axes[2].set_title('Grup 3: Yenilenebilir Enerji ve DiÄŸer Ãœretimler')

    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()


# =============================================================================
# ANA YÃ–NETÄ°CÄ° FONKSÄ°YON (MASTER FUNCTION)
# =============================================================================

def run_full_eda(dataframe, target_col="PTF (TL/MWH)", plot_hists=False):
    """
    TÃ¼m EDA sÃ¼recini tek seferde Ã§alÄ±ÅŸtÄ±rÄ±r.

    Parametreler:
    dataframe: Analiz edilecek pandas DataFrame
    target_col: Hedef deÄŸiÅŸken ismi (Ã–rn: 'PTF (TL/MWH)')
    plot_hists: Numerik deÄŸiÅŸkenlerin histogramlarÄ±nÄ± Ã§izip Ã§izmeyeceÄŸi (True/False)
    """
    df = dataframe.copy()

    # 1. Genel BakÄ±ÅŸ
    data_summary(df)

    # 2. Temizlik (GÃ¼neÅŸ vb.)
    df = clean_negative_values(df, col_name='GÃ¼neÅŸ')

    # 3. DeÄŸiÅŸkenlerin AyrÄ±ÅŸtÄ±rÄ±lmasÄ±
    cat_cols, num_cols, cat_but_car = degisken_analiz(df)

    # 4. Numerik DeÄŸiÅŸken Analizi
    print("\n--- NUMERÄ°K DEÄÄ°ÅKENLERÄ°N ANALÄ°ZÄ° ---")
    for col in num_cols:
        numeric_summary(df, numerical_col=col, plot=plot_hists)

    # 5. Target Analizi
    if target_col in df.columns:
        print(f"\n--- HEDEF DEÄÄ°ÅKEN ({target_col}) ANALÄ°ZÄ° ---")
        for col in num_cols:
            if col != target_col:
                # Target numerik olduÄŸu iÃ§in scatter veya corr bakmak daha mantÄ±klÄ± olsa da
                # mevcut koddaki yapÄ±yÄ± korumak adÄ±na groupby ile Ã¶zet geÃ§iyoruz (eÄŸer kategorik target olsaydÄ±)
                # Ancak sÃ¼rekli (continuous) target iÃ§in korelasyon daha iyidir.
                pass

                # 6. Korelasyon Matrisi
    plot_correlation_matrix(df, num_cols)

    # 7. Fiziksel TutarlÄ±lÄ±k
    df = check_physical_integrity(df)

    # 8. Boxplot Analizi
    plot_all_boxplots(df)

    print("\nâœ… EDA SÃ¼reci TamamlandÄ±.")
    return df

# =============================================================================
# KULLANIM
# =============================================================================

# Tek satÄ±rda Ã§alÄ±ÅŸtÄ±rmak iÃ§in

df_final = run_full_eda(df_final, target_col="PTF (TL/MWH)", plot_hists=True)
#////////////////////////////////////////////////////////////////////////////////////










# =============================================================================
# ADIM 1 Ä°STATÄ°STÄ°K FONKSÄ°YONLARI
# =============================================================================

def check_normality(dataframe, target_col):
    """
    Hedef deÄŸiÅŸkenin Normal DaÄŸÄ±lÄ±ma uyup uymadÄ±ÄŸÄ±nÄ± test eder (K-S Testi, Histogram, Q-Q Plot).
    """
    print(f"\n" + "=" * 50)
    print(f"ğŸ“Š NORMALLÄ°K TESTÄ°: {target_col}")
    print("=" * 50)

    # Veriyi temizle
    data_clean = dataframe[target_col].dropna()

    # 1. Kolmogorov-Smirnov Testi
    # Veriyi standardize edip teste sokuyoruz
    ks_stat, p_value_ks = stats.kstest((data_clean - data_clean.mean()) / data_clean.std(), 'norm')
    print(f"K-S Testi Ä°statistiÄŸi: {ks_stat:.4f}")
    print(f"K-S Testi p-deÄŸeri:    {p_value_ks:.4f}")

    if p_value_ks < 0.05:
        print("-> SonuÃ§: Veri Normal DaÄŸÄ±lÄ±ma UYMUYOR (H0 Red).")
    else:
        print("-> SonuÃ§: Veri Normal DaÄŸÄ±lÄ±ma UYUYOR (H0 Reddedilemez).")

    print(f"Ã‡arpÄ±klÄ±k (Skewness):  {data_clean.skew():.4f}")
    print(f"BasÄ±klÄ±k (Kurtosis):   {data_clean.kurt():.4f}")

    # 2. Histogram ve Teorik Normal EÄŸri
    plt.figure(figsize=(10, 6))
    sns.histplot(data_clean, kde=True, stat="density", color='skyblue', label='GerÃ§ek DaÄŸÄ±lÄ±m')

    mu, std = data_clean.mean(), data_clean.std()
    xmin, xmax = plt.xlim()
    x = np.linspace(xmin, xmax, 100)
    p = norm.pdf(x, mu, std)
    plt.plot(x, p, 'r', linewidth=2, label='Teorik Normal DaÄŸÄ±lÄ±m')
    plt.title(f'{target_col} DaÄŸÄ±lÄ±mÄ± vs Teorik Normal DaÄŸÄ±lÄ±m')
    plt.legend()
    plt.show()

    # 3. Q-Q Plot
    fig = sm.qqplot(data_clean, line='s')
    plt.title(f'{target_col} Ä°Ã§in Q-Q Plot')
    plt.show()


def check_stationarity(dataframe, target_col, plot_cols=None):
    """
    TÃ¼m sayÄ±sal deÄŸiÅŸkenler iÃ§in ADF (Augmented Dickey-Fuller) DuraÄŸanlÄ±k testi yapar.
    """
    print(f"\n" + "=" * 50)
    print("ğŸ“ˆ DURAÄANLIK (STATIONARITY) TESTÄ° - ADF")
    print("=" * 50)

    # Sadece sayÄ±sal sÃ¼tunlarÄ± al (Tarih ve zaman hariÃ§)
    numeric_cols = dataframe.select_dtypes(include=[np.number]).columns
    numeric_cols = [c for c in numeric_cols if c not in ['Tarih', 'Zaman', 'Saat']]

    adf_results = []

    for col in numeric_cols:
        series = dataframe[col].dropna()
        # Sabit varyans varsa test hatasÄ± almamak iÃ§in kontrol
        if series.nunique() <= 1:
            continue

        result = adfuller(series, autolag='AIC')
        p_value = result[1]
        is_stationary = "âœ… Evet" if p_value <= 0.05 else "âŒ HayÄ±r"

        adf_results.append({
            'DeÄŸiÅŸken': col,
            'ADF Stat': round(result[0], 4),
            'p-deÄŸeri': round(p_value, 4),
            'DuraÄŸan mÄ±?': is_stationary
        })

        # Hedef deÄŸiÅŸken iÃ§in detaylÄ± yazdÄ±r
        if col == target_col:
            print(f"--- {target_col} Ä°Ã§in ADF DetayÄ± ---")
            print(f"ADF Ä°statistiÄŸi: {result[0]:.4f}")
            print(f"p-deÄŸeri: {result[1]:.4f}")
            print("Kritik DeÄŸerler:", result[4])
            print(f"SONUÃ‡: Seri {'DURAÄANDIR' if p_value <= 0.05 else 'DuraÄŸan DEÄÄ°LDÄ°R (Trend Var)'}.\n")

    # SonuÃ§ Tablosu
    adf_df = pd.DataFrame(adf_results)
    print("--- TÃ¼m DeÄŸiÅŸkenler Ä°Ã§in Ã–zet Tablo ---")
    print(adf_df)

    # SeÃ§ili DeÄŸiÅŸkenlerin Zaman Serisi GrafiÄŸi
    if plot_cols:
        valid_cols = [c for c in plot_cols if c in dataframe.columns]
        if valid_cols:
            fig, axes = plt.subplots(len(valid_cols), 1, figsize=(12, 4 * len(valid_cols)))
            if len(valid_cols) == 1: axes = [axes]  # Tekli durumda dÃ¶ngÃ¼ hatasÄ± olmasÄ±n

            for i, col in enumerate(valid_cols):
                axes[i].plot(dataframe.index, dataframe[col], color='tab:blue')
                axes[i].set_title(f'{col} - Zaman Serisi GrafiÄŸi')
                axes[i].grid(True, alpha=0.3)
            plt.tight_layout()
            plt.show()


def analyze_volatility(dataframe):
    """
    Belirli gruplar iÃ§in hareketli standart sapma (Volatilite) analizi yapar.
    Hem grafik Ã§izer hem de istatistiksel tabloyu basar.
    """
    print(f"\n" + "=" * 50)
    print("ğŸ“‰ VOLATÄ°LÄ°TE ANALÄ°ZÄ° (24 Saatlik Rolling Std)")
    print("=" * 50)

    groups = {
        "Fiyat ve Kur": ['PTF (TL/MWH)', 'Dolar_Kuru', 'dogalgaz_fiyatlari_Mwh'],
        "Fosil YakÄ±tlar": ['DoÄŸalgaz', 'Linyit', 'Ä°thal KÃ¶mÃ¼r'],
        "Yenilenebilir": ['Akarsu', 'RÃ¼zgar', 'GÃ¼neÅŸ']
    }

    for title, cols in groups.items():
        valid_cols = [c for c in cols if c in dataframe.columns]

        if valid_cols:
            # Hesaplama
            vol_data = dataframe[valid_cols].rolling(window=24).std()

            # --- SAYISAL Ã‡IKTI KISMI (YENÄ° EKLENDÄ°) ---
            print(f"\nğŸ“Š GRUP: {title} - Volatilite Ä°statistikleri")
            print("-" * 45)
            # Ortalama, Max ve Min oynaklÄ±ÄŸÄ± gÃ¶steren tablo
            stats_summary = vol_data.describe().T[['mean', 'std', 'min', 'max']]
            print(stats_summary)

            # Grafik Ã‡izimi
            vol_data.plot(figsize=(12, 5), title=f"{title} Volatilitesi")
            plt.ylabel("Standart Sapma (24s)")
            plt.grid(True, alpha=0.3)
            plt.show()


def analyze_correlation(dataframe, target_col):
    """
    Spearman korelasyonu hesaplar.
    Hem sayÄ±sal listeyi basar hem de Heatmap Ã§izer.
    """
    print(f"\n" + "=" * 50)
    print("ğŸ”— KORELASYON ANALÄ°ZÄ° (Spearman)")
    print("=" * 50)

    num_cols = dataframe.select_dtypes(include=[np.number]).columns

    if len(num_cols) < 2:
        return

    # Hesaplama
    corr_matrix = dataframe[num_cols].corr(method='spearman')

    if target_col in corr_matrix.columns:
        target_corr = corr_matrix[[target_col]].sort_values(by=target_col, ascending=False)

        # --- SAYISAL Ã‡IKTI KISMI (YENÄ° EKLENDÄ°) ---
        print(f"\nğŸ”¢ {target_col} ile Korelasyon KatsayÄ±larÄ± (SÄ±ralÄ± Liste):")
        print("-" * 50)
        # Tabloyu daha okunaklÄ± bas
        print(target_corr)
        print("-" * 50)

        # Grafik Ã‡izimi
        plt.figure(figsize=(6, 10))
        sns.heatmap(target_corr, annot=True, cmap='RdYlGn', fmt=".2f", center=0)
        plt.title(f"{target_col} ile Spearman Korelasyonu")
        plt.show()
    else:
        print(f"Hata: {target_col} korelasyon matrisinde bulunamadÄ±.")


def analyze_vif(dataframe, target_col, drop_list=None):
    """
    Ã‡oklu BaÄŸlantÄ± (Multicollinearity) Analizi - VIF
    4 AÅŸamalÄ± Test Yapar: Raw, Reduced, Scaled, Differenced
    """
    print(f"\n" + "=" * 50)
    print("ğŸ§© Ã‡OKLU BAÄLANTI (VIF) ANALÄ°ZÄ°")
    print("=" * 50)

    # Target hariÃ§ baÄŸÄ±msÄ±z deÄŸiÅŸkenler
    X = dataframe.drop([target_col], axis=1).select_dtypes(include=[np.number])
    # NaN temizliÄŸi
    X = X.dropna()

    def calc_vif(data, label):
        """VIF hesaplayan yardÄ±mcÄ± iÃ§ fonksiyon"""
        if data.shape[1] == 0: return
        vif_df = pd.DataFrame()
        vif_df["DeÄŸiÅŸken"] = data.columns
        vif_df["VIF"] = [variance_inflation_factor(data.values, i) for i in range(data.shape[1])]
        print(f"\n--- {label} ---")
        print(vif_df.sort_values(by="VIF", ascending=False).head(10))  # Ä°lk 10'u gÃ¶ster
        return vif_df

    # 1. Ham Veri VIF
    calc_vif(X, "1. Ham Veri VIF SonuÃ§larÄ±")

    # 2. Belirli DeÄŸiÅŸkenleri Ã‡Ä±kararak VIF
    if drop_list:
        valid_drop = [c for c in drop_list if c in X.columns]
        X_reduced = X.drop(columns=valid_drop)
        calc_vif(X_reduced, "2. Gereksiz DeÄŸiÅŸkenler AtÄ±ldÄ±ktan Sonra VIF")

    # 3. Ã–lÃ§eklenmiÅŸ (Scaled) VIF
    scaler = StandardScaler()
    X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)
    calc_vif(X_scaled, "3. StandardScaler SonrasÄ± VIF")

    # 4. FarkÄ± AlÄ±nmÄ±ÅŸ (Differenced) VIF
    X_diff = X.diff().dropna()
    calc_vif(X_diff, "4. Fark Alma (Differencing) SonrasÄ± VIF")


# =============================================================================
# ANA YÃ–NETÄ°CÄ° FONKSÄ°YON
# =============================================================================

def run_statistical_tests(dataframe, target_col="PTF (TL/MWH)"):
    """
    TÃ¼m istatistiksel testleri sÄ±rayla Ã§alÄ±ÅŸtÄ±rÄ±r.
    """
    df = dataframe.copy()

    # 1. Normallik
    check_normality(df, target_col)

    # 2. DuraÄŸanlÄ±k (ADF)
    # GrafiÄŸi Ã§izilecek kritik deÄŸiÅŸkenler (varsa)
    critical_cols = ['Dolar_Kuru', 'dogalgaz_fiyatlari_Mwh', 'Akarsu', 'Jeotermal']
    check_stationarity(df, target_col, plot_cols=critical_cols)

    # 3. Volatilite
    analyze_volatility(df)

    # 4. Korelasyon
    analyze_correlation(df, target_col)

    # 5. VIF (Ã‡oklu BaÄŸlantÄ±)
    # Ã‡Ä±karÄ±lmasÄ± dÃ¼ÅŸÃ¼nÃ¼len yÃ¼ksek VIF'li deÄŸiÅŸkenler listesi
    cols_to_drop = ['BiyokÃ¼tle', 'Jeotermal', 'Akarsu']
    analyze_vif(df, target_col, drop_list=cols_to_drop)

    print("\nâœ… TÃ¼m Ä°statistiksel Testler TamamlandÄ±.")

# =============================================================================
# KULLANIM
# =============================================================================

# Tek satÄ±rda Ã§alÄ±ÅŸtÄ±rmak iÃ§in:
run_statistical_tests(df_final, target_col="PTF (TL/MWH)")
#////////////////////////////////////////////////////////////////////////////////////









# =============================================================================
#      ADIM 2         --TÄ°ME SERÄ°ES (ZAMAN SERÄ°SÄ°)--
# =============================================================================

def run_time_series_analysis(dataframe, target_col="PTF (TL/MWH)", feature_col="RÃ¼zgar"):
    """
    Zaman Serisi Analizi Paketi (SayÄ±sal Raporlu Versiyon):
    Hem grafik Ã§izer hem de konsola istatistiksel Ã¶zet basar.
    """
    print(f"\n" + "=" * 50)
    print("â³ ZAMAN SERÄ°SÄ° ANALÄ°ZÄ° BAÅLIYOR (SayÄ±sal Raporlu)")
    print("=" * 50)

    df = dataframe.copy()
    series = df[target_col].dropna()

    # =========================================================================
    # 1. ZAMAN BÄ°LGÄ°SÄ° HAZIRLIÄI
    # =========================================================================
    # Saat, GÃ¼n, Ay bilgilerini Ã§Ä±kar
    if 'Saat' in df.columns:
        try:
            df['Hour_Viz'] = df['Saat'].astype(str).str.split(':').str[0].astype(int)
        except:
            df['Hour_Viz'] = df['Saat'].astype(int)
    elif 'Tarih' in df.columns:
        df['Hour_Viz'] = df['Tarih'].dt.hour
    else:
        df['Hour_Viz'] = df.index % 24

    if 'Tarih' in df.columns:
        df['Day_of_Week'] = df['Tarih'].dt.dayofweek
        df['Month'] = df['Tarih'].dt.month
    else:
        df['Day_of_Week'] = df.index.dayofweek
        df['Month'] = df.index.month

    # =========================================================================
    # 2. MEVSÄ°MSELLÄ°K AYRIÅTIRMA (DECOMPOSITION)
    # =========================================================================
    print("\n1. Mevsimsel AyrÄ±ÅŸtÄ±rma (Decomposition)")
    try:
        res = seasonal_decompose(series, model='additive', period=24)

        # --- SAYISAL Ã‡IKTI ---
        print(f"   Ortalama Trend DeÄŸeri: {res.trend.mean():.2f}")
        print(f"   Mevsimsellik Etkisi (Max): {res.seasonal.max():.2f}")
        print(f"   Mevsimsellik Etkisi (Min): {res.seasonal.min():.2f}")

        # Grafik
        plt.rcParams['figure.figsize'] = (14, 10)
        res.plot()
        plt.suptitle(f'{target_col} - 24 Saatlik AyrÄ±ÅŸtÄ±rma', fontsize=16, y=1.02)
        plt.show()
    except Exception as e:
        print(f"âŒ Decomposition hatasÄ±: {e}")

    # =========================================================================
    # 3. ACF ve PACF (OTOKORELASYON)
    # =========================================================================
    print("\n2. Otokorelasyon Analizi")
    print("   (Grafikler oluÅŸturuluyor... ACF: HafÄ±za, PACF: DoÄŸrudan Etki)")

    fig, axes = plt.subplots(2, 2, figsize=(16, 10))
    # 48 Saat
    plot_acf(series, lags=48, ax=axes[0, 0], title='ACF (48 Saat)')
    plot_pacf(series, lags=48, ax=axes[0, 1], method='yw', title='PACF (48 Saat)')
    # 168 Saat
    plot_acf(series, lags=168, ax=axes[1, 0], title='ACF (1 Hafta)')
    plot_pacf(series, lags=168, ax=axes[1, 1], method='yw', title='PACF (1 Hafta)')
    plt.tight_layout()
    plt.show()

    # =========================================================================
    # 4. Ã‡APRAZ KORELASYON (FEATURE vs TARGET)
    # =========================================================================
    if feature_col in df.columns:
        print(f"\n3. Ã‡apraz Korelasyon: {feature_col} vs {target_col}")

        feat_series = df[feature_col].dropna()
        min_len = min(len(series), len(feat_series))
        s1 = series.iloc[:min_len]
        s2 = feat_series.iloc[:min_len]

        cross_corr = [s1.corr(s2.shift(lag)) for lag in range(25)]

        # --- SAYISAL Ã‡IKTI (Ã–NEMLÄ°) ---
        print("-" * 40)
        print(f"   Gecikme (Lag) | Korelasyon KatsayÄ±sÄ±")
        print("-" * 40)
        for i, val in enumerate(cross_corr[:6]):  # Ä°lk 5 saati bas
            print(f"   Lag {i} (Saat)  | {val:.4f}")

        # En gÃ¼Ã§lÃ¼ iliÅŸkiyi bul
        max_idx = np.argmax(np.abs(cross_corr))
        print("-" * 40)
        print(f"ğŸ‘‰ EN GÃœÃ‡LÃœ Ä°LÄ°ÅKÄ°: {max_idx}. Saatte (Corr: {cross_corr[max_idx]:.4f})")
        print("-" * 40)

        # Grafik
        plt.figure(figsize=(10, 5))
        plt.bar(range(25), cross_corr, color='teal')
        plt.title(f'{feature_col} ve {target_col} Gecikmeli Ä°liÅŸki')
        plt.xlabel('Gecikme (Saat)')
        plt.show()
    else:
        print(f"âš ï¸ '{feature_col}' bulunamadÄ±.")

    # =========================================================================
    # 5. HAREKETLÄ° ORTALAMA VE OYNAKLIK
    # =========================================================================
    print("\n4. Trend ve Volatilite Ä°statistikleri")

    rolling_mean = series.rolling(window=24).mean()
    rolling_std = series.rolling(window=24).std()

    # --- SAYISAL Ã‡IKTI ---
    print(f"   Genel Ortalama Fiyat: {series.mean():.2f}")
    print(f"   Ortalama Volatilite (Std): {rolling_std.mean():.2f}")
    print(f"   Maksimum Volatilite: {rolling_std.max():.2f}")

    # Grafik
    plt.figure(figsize=(14, 6))
    plt.plot(series, label='GerÃ§ek', alpha=0.3, color='gray')
    plt.plot(rolling_mean, label='Hareketli Ort.', color='red')
    plt.plot(rolling_std, label='Hareketli Std.', color='blue', linestyle='--')
    plt.title('Trend ve Volatilite')
    plt.legend()
    plt.show()

    # =========================================================================
    # 6. ISI HARÄ°TASI VE DETAYLI TABLO
    # =========================================================================
    print("\n5. Saatlik Fiyat Matrisi (Pivot Tablo)")

    if 'Hour_Viz' in df.columns and 'Day_of_Week' in df.columns:
        pivot_table = df.pivot_table(values=target_col, index='Hour_Viz', columns='Day_of_Week', aggfunc='mean')

        # --- SAYISAL Ã‡IKTI (TABLOYU BAS) ---
        # Okunabilirlik iÃ§in sÃ¼tun isimlerini deÄŸiÅŸtir
        gunler = {0: 'Pzt', 1: 'Sal', 2: 'Ã‡ar', 3: 'Per', 4: 'Cum', 5: 'Cmt', 6: 'Paz'}
        pivot_print = pivot_table.rename(columns=gunler)

        print("\n   Saatlere ve GÃ¼nlere GÃ¶re Ortalama PTF:")
        print(pivot_print.round(2))  # VirgÃ¼lden sonra 2 hane ile tabloyu bas

        # Grafik
        plt.figure(figsize=(10, 6))
        sns.heatmap(pivot_table, cmap='YlOrRd', annot=False)
        plt.title('PTF OrtalamasÄ±: Saat vs GÃ¼n')
        plt.show()

        # Boxplot
        fig, axes = plt.subplots(2, 1, figsize=(15, 12))
        sns.boxplot(x='Hour_Viz', y=target_col, data=df, ax=axes[0], palette="viridis")
        axes[0].set_title('Saat BazlÄ± DaÄŸÄ±lÄ±m')

        if 'Month' in df.columns:
            sns.boxplot(x='Month', y=target_col, data=df, ax=axes[1], palette="magma")
            axes[1].set_title('AylÄ±k DaÄŸÄ±lÄ±m')
        plt.show()
    else:
        print("âš ï¸ Saat verisi eksik.")

    print("\nâœ… Analiz TamamlandÄ±.")


# Ã‡alÄ±ÅŸtÄ±rma
run_time_series_analysis(df_final, target_col="PTF (TL/MWH)", feature_col="RÃ¼zgar")
#////////////////////////////////////////////////////////////////////////////////////









# =============================================================================
#     ADIM 3            --FUTURE ENGENEERÄ°NG--
# =============================================================================
def run_feature_engineering(dataframe):
    """
    Ham veri setini alÄ±r, 'Sniper' Ã¶zellikleri ekler, SÄ±zÄ±ntÄ± (Leakage) kontrolÃ¼ yapar
    ve modele hazÄ±r hale getirir.
    """
    print(f"\n" + "=" * 50)
    print("ğŸ› ï¸ FEATURE ENGINEERING (Ã–ZELLÄ°K MÃœHENDÄ°SLÄ°ÄÄ°) BAÅLIYOR")
    print("=" * 50)

    # Orijinal veriyi bozmamak iÃ§in kopya al
    df = dataframe.copy()

    # -------------------------------------------------------------------------
    # 1. TATÄ°L VE ZAMAN DEÄÄ°ÅKENLERÄ°
    # -------------------------------------------------------------------------
    print("ğŸ“… Takvim ve Tatil Verileri Ä°ÅŸleniyor...")

    # Tarih formatÄ± kontrolÃ¼
    if 'Tarih' not in df.columns:
        if isinstance(df.index, pd.DatetimeIndex):
            df = df.reset_index()
            df.rename(columns={df.columns[0]: 'Tarih'}, inplace=True)
        else:
            print("âŒ HATA: 'Tarih' sÃ¼tunu bulunamadÄ±!")
            return None

    df['Tarih'] = pd.to_datetime(df['Tarih'])

    # Tatil GÃ¼nleri (TÃ¼rkiye)
    try:
        tr_holidays = holidays.TR(years=[2023, 2024, 2025])
        df['Is_Holiday'] = df['Tarih'].apply(lambda x: 1 if x in tr_holidays else 0)
    except Exception as e:
        print(f"âš ï¸ Tatil verisi Ã§ekilemedi: {e}")
        df['Is_Holiday'] = 0

    # Hafta Sonu ve GÃ¼nler
    df['Day_of_Week'] = df['Tarih'].dt.dayofweek
    df['Month'] = df['Tarih'].dt.month
    df['Is_Weekend'] = df['Day_of_Week'].isin([5, 6]).astype(int)

    # Saat DÃ¶nÃ¼ÅŸÃ¼mÃ¼ (DÃ¶ngÃ¼sel Ã–zellikler)
    # Saat sÃ¼tunu yoksa Tarih'ten Ã§ek, varsa iÅŸle
    if 'Saat' in df.columns:
        if df['Saat'].dtype == 'O':  # Object/String ise
            df['Saat_Int'] = df['Saat'].astype(str).str.split(':').str[0].astype(int)
        else:
            df['Saat_Int'] = df['Saat'].astype(int)
    else:
        df['Saat_Int'] = df['Tarih'].dt.hour

    # SinÃ¼s/KosinÃ¼s DÃ¶nÃ¼ÅŸÃ¼mÃ¼ (Saatin 23 ile 00 arasÄ±ndaki yakÄ±nlÄ±ÄŸÄ±nÄ± modele Ã¶ÄŸretmek iÃ§in)
    df['Hour_Sin'] = np.sin(2 * np.pi * df['Saat_Int'] / 24)
    df['Hour_Cos'] = np.cos(2 * np.pi * df['Saat_Int'] / 24)
    df['Day_Sin'] = np.sin(2 * np.pi * df['Day_of_Week'] / 7)
    df['Day_Cos'] = np.cos(2 * np.pi * df['Day_of_Week'] / 7)

    # -------------------------------------------------------------------------
    # 2. SHIFT (LAG) OPERASYONU (GELECEÄÄ° GÃ–RMEYÄ° ENGELLEME)
    # -------------------------------------------------------------------------
    # Bu deÄŸiÅŸkenler gerÃ§ekleÅŸen verilerdir. YarÄ±nÄ± tahmin ederken bugÃ¼nÃ¼n deÄŸerini bilemeyiz.
    # O yÃ¼zden 24 saat Ã¶ncesini (dÃ¼nÃ¼) kullanÄ±yoruz.
    future_cols = ['DoÄŸalgaz', 'RÃ¼zgar', 'GÃ¼neÅŸ', 'BarajlÄ±', 'Linyit',
                   'Ä°thal KÃ¶mÃ¼r', 'Akarsu', 'Fuel Oil', 'Jeotermal', 'BiyokÃ¼tle']

    # Sadece veri setinde var olanlarÄ± seÃ§
    cols_to_shift = [c for c in future_cols if c in df.columns]

    print(f"â³ Shift Ä°ÅŸlemi: {len(cols_to_shift)} Ã¼retim deÄŸiÅŸkeni Ã¶telenecek...")

    for col in cols_to_shift:
        # Zaten Lag24 yapÄ±lmÄ±ÅŸ mÄ± kontrol et (Ã‡ift Ã§alÄ±ÅŸmayÄ± Ã¶nle)
        if f'{col}_Lag24' not in df.columns:
            df[f'{col}_Lag24'] = df[col].shift(24)
            # Orijinal sÃ¼tunu sil (Model kopya Ã§ekmesin)
            df.drop(columns=[col], inplace=True)

    # Trend Analizi (Fark Alma)
    # Ã–rneÄŸin: DoÄŸalgaz dÃ¼ne gÃ¶re arttÄ± mÄ± azaldÄ± mÄ±?
    trend_cols = ['DoÄŸalgaz_Lag24', 'Ä°thal KÃ¶mÃ¼r_Lag24', 'Linyit_Lag24', 'Dolar_Kuru']
    for col in trend_cols:
        if col in df.columns:
            df[f'{col}_Diff'] = df[col].diff()

    # -------------------------------------------------------------------------
    # 3. FÄ°YAT HAFIZASI (TARGET LAGS) - KRÄ°TÄ°K BÃ–LÃœM
    # -------------------------------------------------------------------------
    target_col = 'PTF (TL/MWH)'

    if target_col in df.columns:
        # DÃ¼n bu saatte fiyat neydi?
        df['PTF_Lag_24'] = df[target_col].shift(24)
        # GeÃ§en hafta bu saatte fiyat neydi?
        df['PTF_Lag_168'] = df[target_col].shift(168)

        # --- GÃœVENLÄ° ROLLING (SIZINTI Ã–NLEYÄ°CÄ°) ---
        # Hareketli ortalamayÄ± 'PTF' Ã¼zerinden DEÄÄ°L, 'PTF_Lag_24' Ã¼zerinden alÄ±yoruz.
        # BÃ¶ylece bugÃ¼nÃ¼n verisi hesabÄ±n iÃ§ine karÄ±ÅŸmÄ±yor.
        df['PTF_Roll_Mean_24'] = df['PTF_Lag_24'].rolling(24).mean()
        df['PTF_Roll_Std_24'] = df['PTF_Lag_24'].rolling(24).std()
        df['PTF_Roll_Mean_168'] = df['PTF_Lag_24'].rolling(168).mean()
    else:
        print("âŒ HATA: Hedef deÄŸiÅŸken (PTF) bulunamadÄ±!")
        return None

    # -------------------------------------------------------------------------
    # 4. SNIPER Ã–ZELLÄ°KLER (AKILLI RASYOLAR)
    # -------------------------------------------------------------------------
    print("ğŸ¯ Sniper DeÄŸiÅŸkenler (Rasyolar) OluÅŸturuluyor...")

    # A. Relative Price Position (FiyatÄ±n konumunu normalleÅŸtirir)
    if 'PTF_Roll_Mean_168' in df.columns:
        df['Relative_Price_Pos'] = (df['PTF_Lag_24'] - df['PTF_Roll_Mean_168']) / (df['PTF_Roll_Mean_168'] + 1)

    # B. Price Momentum (HaftalÄ±k DeÄŸiÅŸim HÄ±zÄ±)
    df['Price_Momentum'] = df['PTF_Lag_24'] - df['PTF_Lag_168']

    # C. Net Load (Termik Santrallere Kalan YÃ¼k)
    # Toplam Yenilenebilir Enerji (Shift edilmiÅŸ verilerden!)
    ren_cols = ['RÃ¼zgar_Lag24', 'GÃ¼neÅŸ_Lag24', 'Akarsu_Lag24', 'Jeotermal_Lag24', 'BiyokÃ¼tle_Lag24']
    existing_ren = [c for c in ren_cols if c in df.columns]
    df['Total_Renewable_Lag24'] = df[existing_ren].sum(axis=1)

    load_col = 'YÃ¼k Tahmin PlanÄ± (MWh)'
    if load_col in df.columns:
        df['Net_Load'] = df[load_col] - df['Total_Renewable_Lag24']
    else:
        df['Net_Load'] = -df['Total_Renewable_Lag24']  # YÃ¼k yoksa negatif Ã¼retim

    # D. Thermal Stress (Termik Santrallerin YÃ¼kÃ¼)
    therm_cols = ['DoÄŸalgaz_Lag24', 'Ä°thal KÃ¶mÃ¼r_Lag24', 'Linyit_Lag24', 'Fuel Oil_Lag24']
    existing_therm = [c for c in therm_cols if c in df.columns]
    df['Total_Thermal_Lag24'] = df[existing_therm].sum(axis=1)

    if load_col in df.columns:
        # (Termik Ãœretim / Toplam YÃ¼k) oranÄ±
        df['Thermal_Stress'] = df['Total_Thermal_Lag24'] / (df[load_col] + 1)
    else:
        df['Thermal_Stress'] = 0

    # -------------------------------------------------------------------------
    # 5. TEMÄ°ZLÄ°K VE FÄ°NAL
    # -------------------------------------------------------------------------
    rows_before = len(df)
    df.dropna(inplace=True)
    rows_after = len(df)

    print(f"ğŸ§¹ Temizlik: Ä°lk {rows_before - rows_after} satÄ±r (Lag'lerden dolayÄ± boÅŸ) silindi.")
    print(f"âœ… Modele HazÄ±r SatÄ±r SayÄ±sÄ±: {rows_after}")

    return df

# =============================================================================
# KULLANIM
# =============================================================================
df_final = run_feature_engineering(df_final)
#////////////////////////////////////////////////////////////////////////////////////









# =============================================================================
#    ADIM 4              --MODELLEME--
# =============================================================================

def run_model_training(dataframe, target_col='PTF (TL/MWH)'):
    """
    XGBoost Model EÄŸitimi, Tarih BazlÄ± BÃ¶lÃ¼mleme, Optimizasyon ve Final EÄŸitim.
    (Orijinal kod yapÄ±sÄ± %100 korunmuÅŸtur)
    """
    print(f"\n" + "=" * 50)
    print("ğŸ¤– ADIM 6: MODELLEME (XGBOOST) BAÅLIYOR")
    print("=" * 50)

    df = dataframe.copy()

    # -------------------------------------------------------------------------
    # 1. X (Ã–ZELLÄ°KLER) ve y (HEDEF) AYRIMI
    # -------------------------------------------------------------------------
    # Modelin gÃ¶rmemesi gereken (Drop Listesi) sÃ¼tunlar
    drop_cols = [
        'Tarih',  # Datetime formatÄ±, model iÅŸlemez
        'Zaman',  # Datetime formatÄ±, model iÅŸlemez
        'Saat',  # String/Object formatÄ± veya gereksiz tekrar
        'Saat_Int',  # Hour_Sin/Cos varken bazen gereksiz olabilir
        target_col  # HEDEF DEÄÄ°ÅKEN (SÄ±zÄ±ntÄ±yÄ± Ã¶nlemek iÃ§in X'ten atÄ±yoruz)
    ]

    # Sadece veri setinde mevcut olanlarÄ± drop listesine ekle
    existing_drop_cols = [c for c in drop_cols if c in df.columns]

    # X Matrisi (Girdiler)
    X = df.drop(columns=existing_drop_cols)

    # y VektÃ¶rÃ¼ (Ã‡Ä±ktÄ± / Hedef)
    y = df[target_col]

    # Tarihleri GÃ¶rselleÅŸtirme Ä°Ã§in Sakla
    if 'Tarih' in df.columns:
        dates = df['Tarih']
    else:
        dates = df.index  # EÄŸer tarih index'te ise

    print(f"ğŸš« Drop Edilen SÃ¼tunlar: {existing_drop_cols}")
    print(f"âœ… X Matrisi Boyutu: {X.shape}")
    print(f"ğŸ¯ y Matrisi Boyutu: {y.shape}")

    # -------------------------------------------------------------------------
    # 2. ZAMAN SERÄ°SÄ° BÃ–LÃœMLEME (TRAIN / TEST SPLIT) - TARÄ°H BAZLI
    # -------------------------------------------------------------------------
    train_end_date = '2025-10-31'
    test_start_date = '2025-11-01'
    test_end_date = '2025-11-30'

    # Maskeleme (Filtreleme)
    train_mask = (dates >= '2024-01-01') & (dates <= train_end_date)
    test_mask = (dates >= test_start_date) & (dates <= test_end_date)

    # Veriyi BÃ¶lme
    X_train = X.loc[train_mask]
    X_test = X.loc[test_mask]

    y_train = y.loc[train_mask]
    y_test = y.loc[test_mask]

    # Tarihleri de ayÄ±r
    dates_train = dates.loc[train_mask]
    dates_test = dates.loc[test_mask]

    # KONTROL
    print("-" * 50)
    print(f"ğŸ“‰ EÄŸitim Seti (Train): {len(X_train)} satÄ±r")
    if len(dates_train) > 0:
        print(f"   AralÄ±k: {dates_train.min().date()}  --->  {dates_train.max().date()}")
    print("-" * 50)
    print(f"ğŸ“ˆ Test Seti (Test):    {len(X_test)} satÄ±r")
    if len(dates_test) > 0:
        print(f"   AralÄ±k: {dates_test.min().date()}  --->  {dates_test.max().date()}")
    print("-" * 50)

    # GÃ¼venlik KontrolÃ¼
    if len(X_test) == 0:
        raise ValueError("âš ï¸ HATA: Test seti boÅŸ geldi! Tarih formatlarÄ±nÄ± veya veri aralÄ±ÄŸÄ±nÄ± kontrol et.")

    # -------------------------------------------------------------------------
    # 3. REFERANS NOKTASI (BENCHMARK - NAIVE FORECAST)
    # -------------------------------------------------------------------------
    if 'PTF_Lag_24' in X_test.columns:
        naive_pred = X_test['PTF_Lag_24']
        naive_rmse = np.sqrt(mean_squared_error(y_test, naive_pred))
        naive_mae = mean_absolute_error(y_test, naive_pred)

        print(f"ğŸ›‘ Benchmark (Naive) RMSE: {naive_rmse:.2f} TL")
        print(f"ğŸ›‘ Benchmark (Naive) MAE:  {naive_mae:.2f} TL")
        print("   -> Hedefimiz bu hatalarÄ±n altÄ±na dÃ¼ÅŸmek!")
    else:
        print("âš ï¸ PTF_Lag_24 bulunamadÄ±, Benchmark atlanÄ±yor.")

    # -------------------------------------------------------------------------
    # 4. HÄ°PERPARAMETRE OPTÄ°MÄ°ZASYONU
    # -------------------------------------------------------------------------
    print("\nâš™ï¸ Hiperparametre Optimizasyonu: Overfitting Ã–nleyici Ayarlar...")

    param_dist = {
        'n_estimators': [500, 1000],
        'learning_rate': [0.03, 0.05],
        'max_depth': [3, 4, 5],
        'subsample': [0.7, 0.8],
        'colsample_bytree': [0.7, 0.8],
        'reg_alpha': [0, 0.5, 1],
        'reg_lambda': [1, 5, 10],
        'objective': ['reg:squarederror']
    }

    xgb_model = xgb.XGBRegressor(random_state=42, n_jobs=1)
    tscv = TimeSeriesSplit(n_splits=10)

    random_search = RandomizedSearchCV(
        estimator=xgb_model,
        param_distributions=param_dist,
        n_iter=30,
        scoring='neg_root_mean_squared_error',
        cv=tscv,
        verbose=1,
        random_state=42,
        n_jobs=-1
    )

    random_search.fit(X_train, y_train)
    print(f"\nğŸ† En Ä°yi Parametreler: {random_search.best_params_}")

    # -------------------------------------------------------------------------
    # 5. FÄ°NAL MODELÄ°N EÄÄ°TÄ°LMESÄ°
    # -------------------------------------------------------------------------
    print("\nğŸ¦¾ Final Model EÄŸitiliyor (AkÄ±llÄ± Durdurma Aktif)...")

    best_model = random_search.best_estimator_

    # Parametreyi modele ekliyoruz (set_params yÃ¶ntemiyle)
    best_model.set_params(early_stopping_rounds=50)

    eval_set = [(X_train, y_train), (X_test, y_test)]

    best_model.fit(
        X_train, y_train,
        eval_set=eval_set,
        verbose=False
    )

    print("âœ… Model eÄŸitimi tamamlandÄ±.")

    # DeÄŸerleri dÃ¶ndÃ¼r (Sonraki adÄ±mlar iÃ§in gerekli)
    return best_model, X_train, X_test, y_train, y_test, dates

# =============================================================================
# KULLANIM
# =============================================================================
# Fonksiyonu Ã§alÄ±ÅŸtÄ±r ve Ã§Ä±ktÄ±larÄ± deÄŸiÅŸkenlere ata
best_model, X_train, X_test, y_train, y_test, all_dates = run_model_training(df_final)
#////////////////////////////////////////////////////////////////////////////////////









# =============================================================================
#    ADIM  5           --TAHMÄ°N VE PERFORMANS Ã–LÃ‡ÃœMÃœ (METRICS)--
# =============================================================================

def run_performance_evaluation(model, X_test, y_test, dates_test, naive_rmse):
    """
    EÄŸitilen modelin performansÄ±nÄ± Ã¶lÃ§er, metrikleri hesaplar ve
    gÃ¶rselleÅŸtirme (Tahmin vs GerÃ§ek, Feature Importance) yapar.

    Parametreler:
    model: EÄŸitilmiÅŸ XGBoost modeli (best_model)
    X_test: Test verisi Ã¶zellikleri
    y_test: Test verisi gerÃ§ek deÄŸerleri
    dates_test: Test verisine ait tarihler
    naive_rmse: KÄ±yaslama yapÄ±lacak Benchmark hatasÄ±
    """
    print(f"\n" + "=" * 50)
    print("ğŸ“Š ADIM 7: PERFORMANS DEÄERLENDÄ°RME VE GRAFÄ°KLER")
    print("=" * 50)

    # -------------------------------------------------------------------------
    # 1. TAHMÄ°N YAPMA
    # -------------------------------------------------------------------------
    y_pred = model.predict(X_test)

    # Negatif tahminleri engelle (Fiyat eksi olamaz - istisnalar hariÃ§)
    # (Senin kodundaki mantÄ±k aynen korundu)
    y_pred = np.maximum(y_pred, 0)

    # -------------------------------------------------------------------------
    # 2. METRÄ°K HESAPLAMA (RMSE, MAE, MAPE)
    # -------------------------------------------------------------------------
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mae = mean_absolute_error(y_test, y_pred)

    # MAPE Hesaplama (SÄ±fÄ±ra bÃ¶lme hatasÄ±nÄ± engellemek iÃ§in maskeleme yÃ¶ntemi)
    # (Senin kodundaki mantÄ±k aynen korundu)
    mask = y_test != 0
    mape = (np.abs((y_test - y_pred) / y_test)[mask]).mean() * 100

    # SonuÃ§larÄ± YazdÄ±r
    print("\n" + "=" * 30)
    print("ğŸ“Š FÄ°NAL MODEL SONUÃ‡LARI")
    print("=" * 30)
    print(f"âœ… Model RMSE: {rmse:.2f} TL (Hedef: < {naive_rmse:.2f})")
    print(f"âœ… Model MAE:  {mae:.2f} TL")
    print(f"âœ… Model MAPE: %{mape:.2f}")

    # Ä°yileÅŸme OranÄ± HesabÄ±
    improvement = ((naive_rmse - rmse) / naive_rmse) * 100
    print(f"ğŸš€ Naive Modele GÃ¶re Ä°yileÅŸme: %{improvement:.2f}")

    # -------------------------------------------------------------------------
    # 3. GÃ–RSELLEÅTÄ°RME 1: TAHMÄ°N vs GERÃ‡EK (ZAMAN SERÄ°SÄ°)
    # -------------------------------------------------------------------------
    # Tahminleri DataFrame yapalÄ±m (Tarih indeksiyle)
    df_pred = pd.DataFrame({'GerÃ§ek': y_test, 'Tahmin': y_pred}, index=dates_test)

    # Son 1 HaftayÄ± (168 saat) YakÄ±ndan GÃ¶relim
    last_week = df_pred.iloc[-168:]

    plt.figure(figsize=(15, 6))
    plt.plot(last_week.index, last_week['GerÃ§ek'], label='GerÃ§ek Fiyat (PTF)', color='blue', linewidth=2)
    plt.plot(last_week.index, last_week['Tahmin'], label='XGBoost Tahmini', color='red', linestyle='--', linewidth=2)
    plt.title('Son 1 Hafta: GerÃ§ek vs Tahmin (Zoom In)', fontsize=14)
    plt.ylabel('PTF (TL/MWH)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.show()

    # -------------------------------------------------------------------------
    # 4. GÃ–RSELLEÅTÄ°RME 2: FEATURE IMPORTANCE (Ã–ZELLÄ°K Ã–NEMÄ°)
    # -------------------------------------------------------------------------
    plt.figure(figsize=(10, 8))

    # En Ã¶nemli 20 Ã¶zelliÄŸi Ã§izdir
    # (Modelin feature_importances_ Ã¶zelliÄŸini kullanarak)
    sorted_idx = model.feature_importances_.argsort()[-20:]

    plt.barh(X_test.columns[sorted_idx], model.feature_importances_[sorted_idx], color='purple')
    plt.title("XGBoost: En Ã–nemli DeÄŸiÅŸkenler (Feature Importance)")
    plt.xlabel("Ã–nem DÃ¼zeyi")
    plt.show()


# =============================================================================
# KULLANIM
# =============================================================================
# Bu fonksiyonu Ã§alÄ±ÅŸtÄ±rmak iÃ§in bir Ã¶nceki adÄ±mdan (run_model_training) gelen
# deÄŸiÅŸkenleri kullanacaÄŸÄ±z.

# naive_rmse deÄŸerini loglardan okuyup buraya elle yazabilirsin veya hesaplatabilirsin.
# Ã–nceki Ã§Ä±ktÄ±nda naive_rmse 636.43 Ã§Ä±kmÄ±ÅŸtÄ±.
# Ancak dinamik olmasÄ± iÃ§in kod iÃ§inde hesaplamak en doÄŸrusudur.
naive_rmse_val = np.sqrt(mean_squared_error(y_test, X_test['PTF_Lag_24']))

# Fonksiyonu Ã‡aÄŸÄ±r:
# Not: dates_test deÄŸiÅŸkenini all_dates Ã¼zerinden filtreleyerek oluÅŸturuyoruz.
run_performance_evaluation(
    model=best_model,
    X_test=X_test,
    y_test=y_test,
    dates_test=all_dates.loc[y_test.index],
    naive_rmse=naive_rmse_val
)
# Naive (Benchmark) hatasÄ±nÄ± dinamik olarak hesapla
naive_rmse_val = np.sqrt(mean_squared_error(y_test, X_test['PTF_Lag_24']))

# Performans fonksiyonunu Ã§alÄ±ÅŸtÄ±r
run_performance_evaluation(
    model=best_model,
    X_test=X_test,
    y_test=y_test,
    dates_test=all_dates.loc[y_test.index],
    naive_rmse=naive_rmse_val
)
#////////////////////////////////////////////////////////////////////////////////////









# =============================================================================
#   ADIM 6       --OVERFITTING KONTOL TESTÄ° (TRAIN - TEST)--
# =============================================================================
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error

def run_overfitting_check(model, X_train, X_test, y_train, y_test):
    """
    Modelin EÄŸitim (Train) ve Test (SÄ±nav) verileri arasÄ±ndaki performans farkÄ±nÄ± Ã¶lÃ§er.
    AÅŸÄ±rÄ± Ã¶ÄŸrenme (Overfitting) olup olmadÄ±ÄŸÄ±nÄ± raporlar ve grafikler Ã§izer.
    """
    print(f"\n" + "=" * 50)
    print("ğŸ” ADIM 8: OVERFITTING (AÅIRI Ã–ÄRENME) KONTROLÃœ")
    print("=" * 50)

    # -------------------------------------------------------------------------
    # 1. SKORLARIN HESAPLANMASI
    # -------------------------------------------------------------------------
    # EÄŸitim Seti Tahmini
    y_train_pred = model.predict(X_train)
    y_train_pred = np.maximum(y_train_pred, 0)  # Negatif engeli

    # Test Seti Tahmini
    y_test_pred = model.predict(X_test)
    y_test_pred = np.maximum(y_test_pred, 0)

    # HatalarÄ± Hesapla (RMSE)
    rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))
    rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))

    print(f"ğŸ“˜ EÄŸitim (Train) HatasÄ± (RMSE): {rmse_train:.2f} TL")
    print(f"ğŸ“™ Test (SÄ±nav) HatasÄ± (RMSE):   {rmse_test:.2f} TL")

    # Fark Analizi
    diff = rmse_test - rmse_train
    # SÄ±fÄ±ra bÃ¶lme hatasÄ± Ã¶nlemi
    if rmse_train > 0:
        percentage_diff = (diff / rmse_train) * 100
    else:
        percentage_diff = 0

    print(f"\nâš ï¸ Fark: {diff:.2f} TL (%{percentage_diff:.2f})")

    # Karar MekanizmasÄ±
    if percentage_diff > 50:
        print("SonuÃ§: ğŸš¨ OVERFITTING VAR! (Model eÄŸitim setini ezberlemiÅŸ, testte zorlanÄ±yor.)")
        print("       Ã–neri: 'max_depth' azaltÄ±lmalÄ± veya 'reg_lambda' artÄ±rÄ±lmalÄ±.")
    elif percentage_diff < 0:
        print("SonuÃ§: â“ UNDERFITTING Ä°HTÄ°MALÄ° (Test sonucu eÄŸitimden daha iyi, nadir bir durum.)")
    else:
        print("SonuÃ§: âœ… MODEL SAÄLIKLI (GenelleÅŸtirme yeteneÄŸi baÅŸarÄ±lÄ±.)")

    # -------------------------------------------------------------------------
    # 2. Ã–ÄRENME EÄRÄ°SÄ° (LEARNING CURVE) Ä°Ã‡Ä°N TEKRAR EÄÄ°TÄ°M
    # -------------------------------------------------------------------------
    # Not: XGBoost'un eÄŸitim geÃ§miÅŸini (history) alabilmek iÃ§in eval_set ile
    # modelin Ã¼zerinden bir kez daha geÃ§iyoruz (Re-fit).
    print("\nğŸ©º Modelin EKG'si (Ã–ÄŸrenme EÄŸrisi) Ã‡Ä±karÄ±lÄ±yor...")

    eval_set = [(X_train, y_train), (X_test, y_test)]

    # Mevcut parametreleri koruyarak tekrar fit ediyoruz ki loglarÄ± alabilelim
    model.fit(
        X_train, y_train,
        eval_set=eval_set,
        verbose=False
    )

    results = model.evals_result()

    # Hata yoksa grafik Ã§iz
    if results:
        epochs = len(results['validation_0']['rmse'])
        x_axis = range(0, epochs)

        # -------------------------------------------------------------------------
        # 3. GÃ–RSELLEÅTÄ°RME
        # -------------------------------------------------------------------------
        fig, ax = plt.subplots(1, 2, figsize=(18, 7))

        # GRAFÄ°K 1: Ã–ÄRENME EÄRÄ°SÄ°
        ax[0].plot(x_axis, results['validation_0']['rmse'], label='Train (EÄŸitim)', color='blue', linewidth=2)
        ax[0].plot(x_axis, results['validation_1']['rmse'], label='Test (SÄ±nav)', color='orange', linewidth=2,
                   linestyle='--')
        ax[0].legend()
        ax[0].set_ylabel('RMSE (Hata)')
        ax[0].set_xlabel('AÄŸaÃ§ SayÄ±sÄ± (Iterasyon)')
        ax[0].set_title('Overfitting KontrolÃ¼: Hata EÄŸrileri\n(Ã‡izgiler Birbirine YakÄ±n ve Paralel OlmalÄ±)')
        ax[0].grid(True, alpha=0.3)

        # GRAFÄ°K 2: SCATTER PLOT (EZBER KONTROLÃœ)
        # Noktalar ne kadar Ã§izgi Ã¼zerindeyse o kadar iyi
        ax[1].scatter(y_train, y_train_pred, alpha=0.1, color='blue', label='Train Verisi')
        ax[1].scatter(y_test, y_test_pred, alpha=0.4, color='orange', label='Test Verisi')

        # Ä°deal Ã‡izgi (45 Derece)
        lims = [0, max(y_test.max(), y_train.max())]
        ax[1].plot(lims, lims, 'k-', alpha=0.75, zorder=0, label='Tam Ä°sabet Ã‡izgisi')

        ax[1].set_xlabel('GerÃ§ek Fiyat')
        ax[1].set_ylabel('Tahmin Edilen Fiyat')
        ax[1].set_title('Tahmin TutarlÄ±lÄ±ÄŸÄ±: Train vs Test')
        ax[1].legend()
        ax[1].grid(True, alpha=0.3)

        plt.tight_layout()
        plt.show()
    else:
        print("âš ï¸ UyarÄ±: Model geÃ§miÅŸ verisi (evals_result) alÄ±namadÄ±, grafik Ã§izilemiyor.")

# =============================================================================
# KULLANIM
# =============================================================================
# Bu fonksiyon, bir Ã¶nceki (run_model_training) adÄ±mÄ±ndan gelen Ã§Ä±ktÄ±larÄ± kullanÄ±r.
run_overfitting_check(best_model, X_train, X_test, y_train, y_test)
#////////////////////////////////////////////////////////////////////////////////////









# =============================================================================
#    ADIM 7  --SHAP ANALÄ°ZÄ° (MODEL NEDEN BU KARARI VERDÄ°?)--
# =============================================================================

def run_shap_analysis(model, X_test, dates_test, sample_idx=0, dependence_feature='DoÄŸalgaz_Lag24'):
    """
    SHAP (SHapley Additive exPlanations) kullanarak modelin kararlarÄ±nÄ± aÃ§Ä±klar.

    Parametreler:
    model: EÄŸitilmiÅŸ XGBoost modeli
    X_test: Test verisi (DataFrame)
    dates_test: Test verisinin tarihleri
    sample_idx: Tekil analiz (Waterfall) yapÄ±lacak satÄ±r indeksi (veya 'max' / 'random')
    dependence_feature: Ä°liÅŸki grafiÄŸi Ã§izilecek Ã¶zellik ismi
    """
    print(f"\n" + "=" * 50)
    print("ğŸ•µï¸â€â™‚ï¸ ADIM 9: SHAP ANALÄ°ZÄ° (KARAR MEKANÄ°ZMASI)")
    print("=" * 50)

    # 1. Explainer OluÅŸturma
    # TreeExplainer, aÄŸaÃ§ tabanlÄ± modeller iÃ§in en hÄ±zlÄ±sÄ±dÄ±r.
    try:
        explainer = shap.TreeExplainer(model)
        shap_values = explainer(X_test)
    except Exception as e:
        print(f"âŒ SHAP hesaplanÄ±rken hata oluÅŸtu: {e}")
        return

    # -------------------------------------------------------------------------
    # GRAFÄ°K 1: SHAP SUMMARY PLOT (GENEL BAKIÅ)
    # -------------------------------------------------------------------------
    print("\n1. Ã–zet Grafik (Summary Plot) Ã‡iziliyor...")
    print("   (KÄ±rmÄ±zÄ±: YÃ¼ksek DeÄŸer, Mavi: DÃ¼ÅŸÃ¼k DeÄŸer -> SaÄŸa: Fiyat ArtÄ±ÅŸÄ±, Sola: DÃ¼ÅŸÃ¼ÅŸ)")

    plt.figure(figsize=(12, 10))
    shap.summary_plot(shap_values, X_test, show=False)
    plt.title("SHAP Ã–zeti: Hangi Ã–zellik FiyatÄ± NasÄ±l Etkiliyor?", fontsize=16)
    plt.show()

    # -------------------------------------------------------------------------
    # GRAFÄ°K 2: WATERFALL PLOT (TEKÄ°L ANALÄ°Z)
    # -------------------------------------------------------------------------
    # Ä°ndeks Belirleme MantÄ±ÄŸÄ±
    idx = 0
    if sample_idx == 'max':
        # Modelin en yÃ¼ksek fiyat tahmin ettiÄŸi saati bul
        preds = model.predict(X_test)
        idx = np.argmax(preds)
        print(f"\nğŸ“ Analiz Modu: EN YÃœKSEK FÄ°YAT TAHMÄ°NÄ° SEÃ‡Ä°LDÄ° (Ä°ndeks: {idx})")
    elif sample_idx == 'random':
        idx = np.random.randint(0, len(X_test))
        print(f"\nğŸ“ Analiz Modu: RASTGELE SAAT SEÃ‡Ä°LDÄ° (Ä°ndeks: {idx})")
    else:
        idx = int(sample_idx)

    # Tarih ve Tahmin Bilgisi
    # predict fonksiyonu numpy array dÃ¶nebilir, tek deÄŸeri almak iÃ§in [idx]
    current_pred = model.predict(X_test.iloc[[idx]])[0]
    current_date = dates_test.iloc[idx]

    print(f"\n2. Tekil Tahmin Analizi (Waterfall Plot)")
    print(f"   ğŸ” Ä°ncelenen Tarih: {current_date}")
    print(f"   ğŸ” Modelin Tahmini: {current_pred:.2f} TL")

    plt.figure(figsize=(10, 6))
    # max_display=15: En etkili 15 nedeni gÃ¶ster
    shap.plots.waterfall(shap_values[idx], max_display=15, show=False)
    plt.title(f"Fiyat Neden BÃ¶yle Ã‡Ä±ktÄ±? ({current_date})", fontsize=14)
    plt.show()

    # -------------------------------------------------------------------------
    # GRAFÄ°K 3: DEPENDENCE PLOT (Ä°LÄ°ÅKÄ° ANALÄ°ZÄ°)
    # -------------------------------------------------------------------------
    print(f"\n3. BaÄŸÄ±mlÄ±lÄ±k GrafiÄŸi (Dependence Plot): {dependence_feature}")

    if dependence_feature in X_test.columns:
        plt.figure(figsize=(10, 6))
        # interaction_index='auto': SHAP, renklendirmek iÃ§in en alakalÄ± ikinci deÄŸiÅŸkeni otomatik seÃ§er
        shap.plots.scatter(shap_values[:, dependence_feature], color=shap_values, show=False)
        plt.title(f"Ä°liÅŸki Analizi: {dependence_feature} vs Fiyat Etkisi", fontsize=14)
        plt.show()
    else:
        print(f"âš ï¸ UyarÄ±: '{dependence_feature}' sÃ¼tunu bulunamadÄ±, grafik atlanÄ±yor.")

    print("\nâœ… SHAP Analizi TamamlandÄ±.")

# =============================================================================
# KULLANIM (DÃœZELTÄ°LMÄ°Å)
# =============================================================================

# 1. Test Tarihlerini GÃ¼venli Åekilde HazÄ±rla (Ä°ndeks hatasÄ±nÄ± Ã¶nlemek iÃ§in)
# X_test'i oluÅŸtururken kullandÄ±ÄŸÄ±mÄ±z tarih aralÄ±ÄŸÄ±nÄ±n aynÄ±sÄ±nÄ± kullanÄ±yoruz.
dates_test = all_dates[(all_dates >= '2025-11-01') & (all_dates <= '2025-11-30')]

# 2. Fonksiyonu Ã‡alÄ±ÅŸtÄ±r
run_shap_analysis(
    model=best_model,
    X_test=X_test,
    dates_test=dates_test,  # DÃ¼zeltilmiÅŸ tarih serisi
    sample_idx='max',       # En yÃ¼ksek fiyatlÄ± saati inceler
    dependence_feature='DoÄŸalgaz_Lag24'
)
#////////////////////////////////////////////////////////////////////////////////////









# =============================================================================
#  ADIM 8 --ARALIK 2025 SENARYO TAHMÄ°NÄ° (FÄ°NAL DÃœZELTÄ°LMÄ°Å VE BÄ°RLEÅTÄ°RÄ°LMÄ°Å SÃœRÃœM)--
# =============================================================================

def run_forecast_december(model, X_last_month, y_last_month, dates_last_month):
    """
    EÄŸitilen modeli kullanarak AralÄ±k 2025 iÃ§in saatlik tahminler Ã¼retir.
    Ã–zyinelemeli (Recursive) tahmin mantÄ±ÄŸÄ± kullanÄ±lÄ±r.

    Parametreler:
    model: EÄŸitilmiÅŸ XGBoost modeli (best_model)
    X_last_month: Son ayÄ±n (KasÄ±m) Ã¶zellik verisi (X_test)
    y_last_month: Son ayÄ±n gerÃ§ek fiyatlarÄ± (y_test)
    dates_last_month: Son ayÄ±n tarihleri
    """
    print(f"\n" + "=" * 50)
    print("ğŸ”® ADIM 10: ARALIK 2025 SENARYO TAHMÄ°NÄ°")
    print("=" * 50)

    # 1. ARALIK AYI Ä°Ã‡Ä°N BOÅ ÅABLON OLUÅTURMA
    # -------------------------------------------------------------------------
    future_dates = pd.date_range(start='2025-12-01 00:00', end='2025-12-31 23:00', freq='h')
    print(f"ğŸ“… Hedef DÃ¶nem: {len(future_dates)} Saat ({future_dates.min()} - {future_dates.max()})")

    # X_test verisinden kopya al (Åablon olarak kullanacaÄŸÄ±z)
    temp_X = X_last_month.copy()

    # SatÄ±r sayÄ±sÄ±nÄ± eÅŸitleme (720 -> 744 saat)
    missing_hours = len(future_dates) - len(temp_X)

    if missing_hours > 0:
        # Eksik kÄ±sÄ±m kadar veriyi son gÃ¼nden kopyala ekle
        padding = temp_X.iloc[-missing_hours:].copy()
        future_X = pd.concat([temp_X, padding], axis=0)
    else:
        # Fazlaysa kes (Nadir durum)
        future_X = temp_X.iloc[-len(future_dates):].copy()

    # Ä°ndeksi AralÄ±k ayÄ± yap
    future_X.index = future_dates

    # 2. TARÄ°HSEL Ã–ZELLÄ°KLERÄ° GÃœNCELLEME
    # -------------------------------------------------------------------------
    print("âš™ï¸ Tarih ve Tatil Ã¶zellikleri gÃ¼ncelleniyor...")

    # GeÃ§ici 'Saat_Int' oluÅŸtur (Sin/Cos hesabÄ± iÃ§in)
    future_X['Saat_Int'] = future_dates.hour

    # Takvim Ã¶zellikleri
    if 'Month' in future_X.columns: future_X['Month'] = 12
    future_X['Day_of_Week'] = future_dates.dayofweek
    future_X['Is_Weekend'] = future_X['Day_of_Week'].isin([5, 6]).astype(int)

    # Trigonometrik DÃ¶nÃ¼ÅŸÃ¼mler
    if 'Hour_Sin' in future_X.columns:
        future_X['Hour_Sin'] = np.sin(2 * np.pi * future_X['Saat_Int'] / 24)
        future_X['Hour_Cos'] = np.cos(2 * np.pi * future_X['Saat_Int'] / 24)
    if 'Day_Sin' in future_X.columns:
        future_X['Day_Sin'] = np.sin(2 * np.pi * future_X['Day_of_Week'] / 7)
        future_X['Day_Cos'] = np.cos(2 * np.pi * future_X['Day_of_Week'] / 7)

    # Tatil GÃ¼nleri
    tr_holidays = holidays.TR(years=[2025])
    if 'Is_Holiday' in future_X.columns:
        future_X['Is_Holiday'] = future_dates.to_series().apply(lambda x: 1 if x in tr_holidays else 0)

    # Temizlik (Model eÄŸitilirken olmayan sÃ¼tunlarÄ± at)
    if 'Saat_Int' in future_X.columns:
        future_X.drop(columns=['Saat_Int'], inplace=True)

    # 3. Ã–ZYÄ°NELEMELÄ° TAHMÄ°N DÃ–NGÃœSÃœ (RECURSIVE FORECASTING)
    # -------------------------------------------------------------------------
    print("â³ SimÃ¼lasyon BaÅŸlÄ±yor (Bu iÅŸlem biraz sÃ¼rebilir)...")

    future_preds = []
    # BaÅŸlangÄ±Ã§ hafÄ±zasÄ±: KasÄ±m ayÄ±nÄ±n son 1 haftasÄ±
    last_known_prices = y_last_month.iloc[-168:].values.tolist()

    for i in range(len(future_X)):
        # Tek satÄ±r al (DataFrame olarak kalmalÄ±)
        current_row = future_X.iloc[[i]].copy()

        # --- DÄ°NAMÄ°K GÃœNCELLEME (Feature Engineering'in DevamÄ±) ---
        # Model tahmini yapabilmek iÃ§in "DÃ¼n fiyat neydi?" sorusunun cevabÄ±nÄ±
        # bir Ã¶nceki tahminimizden alÄ±p buraya koymalÄ±yÄ±z.

        # Lag 24 (DÃ¼n)
        if 'PTF_Lag_24' in current_row.columns:
            current_row['PTF_Lag_24'] = last_known_prices[-24]

        # Lag 168 (GeÃ§en Hafta)
        if 'PTF_Lag_168' in current_row.columns:
            current_row['PTF_Lag_168'] = last_known_prices[-168]

        # Hareketli Ortalamalar
        if 'PTF_Roll_Mean_24' in current_row.columns:
            current_row['PTF_Roll_Mean_24'] = np.mean(last_known_prices[-24:])

        # Sniper Ã–zellikler (Rasyolar)
        if 'Relative_Price_Pos' in current_row.columns:
            roll_168 = np.mean(last_known_prices[-168:])
            denom = roll_168 if roll_168 != 0 else 1
            current_row['Relative_Price_Pos'] = (current_row['PTF_Lag_24'] - roll_168) / denom

        if 'Price_Momentum' in current_row.columns:
            current_row['Price_Momentum'] = current_row['PTF_Lag_24'] - current_row['PTF_Lag_168']

        # TAHMÄ°N YAP
        pred = model.predict(current_row)[0]
        pred = max(0, pred)  # Negatif fiyat engeli

        # Tahmini listeye ekle (Gelecek adÄ±mlar iÃ§in hafÄ±zaya al)
        future_preds.append(pred)
        last_known_prices.append(pred)

    print("âœ… AralÄ±k ayÄ± tahmini tamamlandÄ±.")

    # 4. SONUÃ‡LARI KAYDETME VE GÃ–RSELLEÅTÄ°RME
    # -------------------------------------------------------------------------
    df_forecast = pd.DataFrame({'Tahmin_Aralik': future_preds}, index=future_dates)

    # Ä°statistiksel Ã–zet
    print(f"\nğŸ“¢ AralÄ±k 2025 Tahmin Ã–zeti:")
    print(f"   Min Fiyat: {df_forecast['Tahmin_Aralik'].min():.2f} TL")
    print(f"   Max Fiyat: {df_forecast['Tahmin_Aralik'].max():.2f} TL")
    print(f"   Ort Fiyat: {df_forecast['Tahmin_Aralik'].mean():.2f} TL")

    # Grafik Ã‡izimi
    plt.figure(figsize=(16, 6))

    # GeÃ§miÅŸ (KasÄ±m Sonu - Mavi)
    last_week_dates = dates_last_month.iloc[-168:]
    last_week_values = y_last_month.iloc[-168:]

    plt.plot(last_week_dates, last_week_values, label='GerÃ§ekleÅŸen (KasÄ±m Sonu)', color='navy', alpha=0.7)

    # Gelecek (AralÄ±k - KÄ±rmÄ±zÄ±)
    plt.plot(df_forecast.index, df_forecast['Tahmin_Aralik'], label='Forecast (AralÄ±k 2025)', color='red')

    # Ortalama Ã‡izgisi
    plt.axhline(df_forecast['Tahmin_Aralik'].mean(), color='green', linestyle='--', label='AralÄ±k OrtalamasÄ±')

    plt.title('AralÄ±k 2025: Gelecek Fiyat Tahmin Senaryosu')
    plt.ylabel('PTF (TL/MWH)')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # Tarih formatÄ±
    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%d-%m'))
    plt.gcf().autofmt_xdate()
    plt.show()

    # 5. EXCEL KAYDI (OPSÄ°YONEL AMA Ã–NEMLÄ°)
    # -------------------------------------------------------------------------
    try:
        df_forecast.to_excel("Aralik_2025_Tahminleri.xlsx")
        print("\nğŸ’¾ Dosya Kaydedildi: Aralik_2025_Tahminleri.xlsx")
    except:
        print("\nâš ï¸ UyarÄ±: Excel dosyasÄ± kaydedilemedi (Dosya aÃ§Ä±k olabilir).")

    return df_forecast

# =============================================================================
# KULLANIM
# =============================================================================
# Bu fonksiyonu Ã§alÄ±ÅŸtÄ±rmak iÃ§in 1. tarihler, 2. X_test ve 3. y_test gereklidir.
# dates_test deÄŸiÅŸkenini daha Ã¶nce oluÅŸturmuÅŸtuk.

dates_test_fixed = all_dates[(all_dates >= '2025-11-01') & (all_dates <= '2025-11-30')]

df_aralik_tahmin = run_forecast_december(
    model=best_model,
    X_last_month=X_test,
    y_last_month=y_test,
    dates_last_month=dates_test_fixed
)
#////////////////////////////////////////////////////////////////////////////////////









# =============================================================================
#   ADIM 9    --RESÄ°DUAL ANALÄ°ZÄ° VE GÃœVENÄ°LÄ°RLÄ°K TESTÄ°--
# =============================================================================
# =============================================================================
# ADIM 9.1: RESIDUAL (HATA) ANALÄ°ZÄ°
# =============================================================================
def run_residual_analysis(y_test, y_pred):
    """
    Modelin hata analizini yapar, istatistiksel metrikleri hesaplar,
    4'lÃ¼ tanÄ± grafiÄŸi Ã§izer ve modelin gÃ¼venilirliÄŸini yorumlar.

    Geri DÃ¶ndÃ¼rÃ¼r: residuals (Hata serisi)
    """
    print(f"\n" + "=" * 50)
    print("ğŸ•µï¸â€â™‚ï¸ ADIM 9: MODEL HATA ANALÄ°ZÄ° VE GÃœVENÄ°LÄ°RLÄ°K TESTÄ°")
    print("=" * 50)

    # Not: GeleceÄŸin gerÃ§eÄŸini bilmediÄŸimiz iÃ§in 'Test Seti' Ã¼zerinden analiz yapÄ±yoruz.

    # 1. HatalarÄ± Hesapla
    # -----------------------------------------------------------------------------
    residuals = y_test - y_pred

    # Ä°statistiksel Metrikler (Ä°ki kodun birleÅŸimi)
    mean_resid = np.mean(residuals)
    std_resid = np.std(residuals)
    min_resid = np.min(residuals)
    max_resid = np.max(residuals)
    skewness = stats.skew(residuals)
    kurtosis = stats.kurtosis(residuals)
    dw_score = durbin_watson(residuals)

    print(f"ğŸ“Š Ä°STATÄ°STÄ°KSEL Ã–ZET:")
    print(f"   Hata OrtalamasÄ± (Bias): {mean_resid:.2f} TL (0'a ne kadar yakÄ±nsa o kadar iyi)")
    print(f"   Standart Sapma:         {std_resid:.2f}")
    print(f"   Min Hata / Max Hata:    {min_resid:.2f} / {max_resid:.2f}")
    print(f"   Ã‡arpÄ±klÄ±k (Skewness):   {skewness:.2f} (0 ideal)")
    print(f"   BasÄ±klÄ±k (Kurtosis):    {kurtosis:.2f} (YÃ¼ksekse 'ÅiÅŸman Kuyruk' var demektir)")
    print(f"   Durbin-Watson Score:    {dw_score:.2f} (2.00 Ä°deal, 1.5-2.5 arasÄ± kabul)")

    # 2. GÃ–RSELLEÅTÄ°RME (4'lÃ¼ Panel)
    # -----------------------------------------------------------------------------
    # Seaborn stilini ayarla (Daha ÅŸÄ±k gÃ¶rÃ¼nÃ¼m iÃ§in)
    sns.set(style="whitegrid")

    fig, axes = plt.subplots(2, 2, figsize=(18, 12))
    fig.suptitle('Model GÃ¼venilirlik Testi (Residual Diagnostics)', fontsize=16, fontweight='bold')

    # GRAFÄ°K A: Residuals vs Time (HatalarÄ±n Zamana GÃ¶re DaÄŸÄ±lÄ±mÄ±)
    axes[0, 0].plot(residuals.index, residuals, color='purple', alpha=0.7, linewidth=1)
    axes[0, 0].axhline(0, color='black', linestyle='--', linewidth=2)
    axes[0, 0].set_title('1. HatalarÄ±n Zaman Ä°Ã§indeki DeÄŸiÅŸimi (Rastgele OlmalÄ±)')
    axes[0, 0].set_ylabel('Hata (TL)')

    # GRAFÄ°K B: Residuals vs Predicted (Heteroskedasite KontrolÃ¼)
    axes[0, 1].scatter(y_pred, residuals, alpha=0.5, color='teal', edgecolor='k', s=30)
    axes[0, 1].axhline(0, color='black', linestyle='--', linewidth=2)
    axes[0, 1].set_title('2. Hata vs Tahmin (Heteroskedasite KontrolÃ¼)')
    axes[0, 1].set_xlabel('Tahmin Edilen Fiyat')
    axes[0, 1].set_ylabel('Hata')

    # GRAFÄ°K C: Histogram (Hata DaÄŸÄ±lÄ±mÄ±)
    sns.histplot(residuals, kde=True, ax=axes[1, 0], color='orange', bins=40, line_kws={'linewidth': 2})
    axes[1, 0].axvline(0, color='black', linestyle='--', linewidth=2)
    axes[1, 0].set_title('3. Hata DaÄŸÄ±lÄ±mÄ± (Ã‡an EÄŸrisi Beklenir)')
    axes[1, 0].set_xlabel('Hata MiktarÄ± (TL)')

    # GRAFÄ°K D: Q-Q Plot (Normallik Testi)
    stats.probplot(residuals, dist="norm", plot=axes[1, 1])
    axes[1, 1].get_lines()[0].set_color('blue')  # Noktalar
    axes[1, 1].get_lines()[0].set_markersize(5)
    axes[1, 1].get_lines()[1].set_color('red')  # Ä°deal Ã‡izgi
    axes[1, 1].get_lines()[1].set_linewidth(2)
    axes[1, 1].set_title('4. Q-Q Plot (Normallik Testi)')

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.show()

    # 3. YORUM VE SONUÃ‡ RAPORU (Otomatik Yorumlama)
    # -----------------------------------------------------------------------------
    print("\nğŸ“¢ MODEL GÃœVENÄ°LÄ°RLÄ°K RAPORU:")

    # Bias (YanlÄ±lÄ±k) KontrolÃ¼
    if abs(mean_resid) < 50:
        print("   âœ… BAÅARILI (Bias): Modelin hata ortalamasÄ± 0'a yakÄ±n. YanlÄ±lÄ±k yok.")
    else:
        print("   âš ï¸ UYARI (Bias): Modelde sistematik bir kayma var.")

    # Skewness (Simetri) KontrolÃ¼
    if abs(skewness) < 0.5:
        print("   âœ… BAÅARILI (Simetri): Hatalar Normal daÄŸÄ±lÄ±ma yakÄ±n. Model tarafsÄ±z.")
    elif skewness > 0:
        print("   âš ï¸ UYARI (Simetri): Pozitif Ã‡arpÄ±klÄ±k. Model fiyatlarÄ± bazen olduÄŸundan DÃœÅÃœK tahmin ediyor.")
    else:
        print("   âš ï¸ UYARI (Simetri): Negatif Ã‡arpÄ±klÄ±k. Model fiyatlarÄ± bazen olduÄŸundan YÃœKSEK tahmin ediyor.")

    # Kurtosis (UÃ§ DeÄŸer) KontrolÃ¼
    if kurtosis > 3:
        print("   â„¹ï¸ BÄ°LGÄ° (UÃ§ DeÄŸerler): 'ÅiÅŸman Kuyruk' var. Model nadiren de olsa bÃ¼yÃ¼k hata (Spike) yapabilir.")

        # --- YENÄ° YORUM: DURBIN-WATSON ---
        if 1.5 <= dw_score <= 2.5:
            print("   âœ… BAÅARILI (Otokorelasyon): Durbin-Watson skoru ideal. Hatalar baÄŸÄ±msÄ±z.")
        else:
            print(f"   âš ï¸ UYARI (Otokorelasyon): Durbin-Watson {dw_score:.2f}. Hatalar arasÄ±nda iliÅŸki olabilir.")

    # Hesaplanan hatalarÄ± geri dÃ¶ndÃ¼r (Belki Excel'e kaydetmek istersin)
    return residuals


# =============================================================================
# ADIM 9.2:   MODEL GÃœVENÄ°LÄ°RLÄ°K VE ROBUSTNESS (SAÄLAMLIK) TESTÄ°
# =============================================================================

# UyarÄ±larÄ± kapatalÄ±m (Temiz Ã§Ä±ktÄ± iÃ§in)
warnings.filterwarnings("ignore")

def run_reliability_tests(model, X_full, y_full, date_series):
    """
    Modeli zorlu ÅŸartlarda test eder:
    1. Mevsimsel Backtest (FarklÄ± aylarda nasÄ±l?)
    2. DuyarlÄ±lÄ±k (Sensitivity) (Girdiler deÄŸiÅŸince tepki veriyor mu?)
    3. Stres Testi (Ekstrem senaryolar)
    4. GÃ¼ven AralÄ±ÄŸÄ± GrafiÄŸi
    """
    print("\n" + "=" * 50)
    print("ğŸ›¡ï¸ ADIM 9.5: MODEL GÃœVENÄ°LÄ°RLÄ°K VE ROBUSTNESS RAPORU")
    print("=" * 50)

    # -------------------------------------------------------------------------
    # TEST 1: BACKTESTING (MEVSÄ°MSEL DAYANIKLILIK TESTÄ°)
    # -------------------------------------------------------------------------
    print("\nğŸ§ª TEST 1: BACKTESTING (Mevsimsel Kontrol)")
    print("-" * 40)

    # Test edilecek dÃ¶nemler (Veri setinde bu tarihlerin olduÄŸundan emin olmalÄ±yÄ±z)
    test_periods = [
        ("ğŸŒ¸ Ä°lkbahar (Nisan 2025)", '2025-04-01', '2025-04-30'),
        ("â˜€ï¸ Yaz Zirvesi (Temmuz 2025)", '2025-07-01', '2025-07-31'),
        ("ğŸ‚ Sonbahar/Test (KasÄ±m 2025)", '2025-11-01', '2025-11-30')
    ]

    for label, start_date, end_date in test_periods:
        # Tarih maskesi oluÅŸtur
        mask = (date_series >= start_date) & (date_series <= end_date)

        if mask.sum() == 0:
            print(f"âš ï¸ {label}: Veri bulunamadÄ±! (AtlanÄ±yor)")
            continue

        X_period = X_full.loc[mask]
        y_period = y_full.loc[mask]

        # Tahmin
        preds = model.predict(X_period)
        preds = np.maximum(preds, 0)

        # Metrikler
        if len(y_period) > 0:
            rmse_period = np.sqrt(mean_squared_error(y_period, preds))
            # +1 sÄ±fÄ±ra bÃ¶lme hatasÄ± iÃ§in
            mape_period = np.mean(np.abs((y_period - preds) / (y_period + 1))) * 100
            print(f"ğŸ“… {label:<30} | RMSE: {rmse_period:.2f} TL | MAPE: %{mape_period:.2f}")
        else:
            print(f"âš ï¸ {label}: Veri yetersiz.")

    print("\nâœ… YORUM: MAPE deÄŸerleri %15-25 bandÄ±ndaysa model mevsimsellikten etkilenmiyor demektir.")

    # -------------------------------------------------------------------------
    # TEST 2: SENSITIVITY ANALYSIS (DUYARLILIK ANALÄ°ZÄ°)
    # -------------------------------------------------------------------------
    print("\nğŸ§ª TEST 2: SENSITIVITY (DuyarlÄ±lÄ±k Analizi)")
    print("-" * 40)

    # Test iÃ§in KasÄ±m ayÄ±nÄ± baz alalÄ±m (En gÃ¼ncel ve stabil)
    mask_nov = (date_series >= '2025-11-01') & (date_series <= '2025-11-30')

    if mask_nov.sum() > 0:
        X_test_sample = X_full.loc[mask_nov].copy()
        base_preds = model.predict(X_test_sample)
        base_mean = np.mean(base_preds)

        # DeÄŸiÅŸtirilecek Kritik Kolonlar
        target_cols = ['YÃ¼k Tahmin PlanÄ± (MWh)', 'Dolar_Kuru', 'DoÄŸalgaz_Lag24']

        for col in target_cols:
            if col in X_test_sample.columns:
                # Senaryo: DeÄŸiÅŸkeni %10 artÄ±r (Ceteris Paribus)
                X_shocked = X_test_sample.copy()
                X_shocked[col] = X_shocked[col] * 1.10

                shocked_preds = model.predict(X_shocked)
                shocked_mean = np.mean(shocked_preds)

                change_pct = ((shocked_mean - base_mean) / base_mean) * 100

                # YÃ¶n kontrolÃ¼
                direction = "â¬†ï¸ ArtÄ±ÅŸ" if change_pct > 0 else "â¬‡ï¸ DÃ¼ÅŸÃ¼ÅŸ"
                # MantÄ±k: YÃ¼k ve Dolar artarsa fiyat artmalÄ±
                logic = "âœ… MantÄ±klÄ±" if change_pct > 0 else "â“ Ä°lginÃ§"

                print(f"ğŸ“Š {col:<25} (+%10) -> Fiyat Etkisi: %{change_pct:+.2f} ({direction}) {logic}")
            else:
                print(f"âš ï¸ {col} sÃ¼tunu bulunamadÄ±, atlanÄ±yor.")
    else:
        print("âš ï¸ KasÄ±m ayÄ± verisi bulunamadÄ±ÄŸÄ± iÃ§in Sensitivity testi yapÄ±lamadÄ±.")

    # -------------------------------------------------------------------------
    # TEST 3: SCENARIO ANALYSIS (EKSTREM DURUM TESTÄ°)
    # -------------------------------------------------------------------------
    print("\nğŸ§ª TEST 3: SCENARIO ANALYSIS (Stres Testi)")
    print("-" * 40)

    # Ortalama bir satÄ±r alÄ±p sadece ilgilendiÄŸimiz deÄŸerleri deÄŸiÅŸtireceÄŸiz
    base_row = X_full.mean().to_frame().T

    # Senaryo 1: KIÅ GECESÄ° KABUSU (YÃ¼ksek YÃ¼k, DÃ¼ÅŸÃ¼k RÃ¼zgar, PahalÄ± Gaz)
    nightmare_row = base_row.copy()
    if 'YÃ¼k Tahmin PlanÄ± (MWh)' in base_row.columns: nightmare_row['YÃ¼k Tahmin PlanÄ± (MWh)'] = 50000
    if 'RÃ¼zgar_Lag24' in base_row.columns: nightmare_row['RÃ¼zgar_Lag24'] = 100
    if 'DoÄŸalgaz_Lag24' in base_row.columns: nightmare_row['DoÄŸalgaz_Lag24'] = 15000

    # Senaryo 2: BAHAR BAYRAMI (DÃ¼ÅŸÃ¼k YÃ¼k, YÃ¼ksek Yenilenebilir)
    paradise_row = base_row.copy()
    if 'YÃ¼k Tahmin PlanÄ± (MWh)' in base_row.columns: paradise_row['YÃ¼k Tahmin PlanÄ± (MWh)'] = 20000
    if 'RÃ¼zgar_Lag24' in base_row.columns: paradise_row['RÃ¼zgar_Lag24'] = 8000
    if 'GÃ¼neÅŸ_Lag24' in base_row.columns: paradise_row['GÃ¼neÅŸ_Lag24'] = 5000

    try:
        pred_nightmare = model.predict(nightmare_row)[0]
        pred_paradise = model.predict(paradise_row)[0]

        print(f"ğŸ”¥ Kabus Senaryosu (YÃ¼ksek Talep/Az RÃ¼zgar): {pred_nightmare:.2f} TL")
        print(f"ğŸŒ¼ Cennet Senaryosu (DÃ¼ÅŸÃ¼k Talep/Bol GÃ¼neÅŸ):  {pred_paradise:.2f} TL")

        if pred_nightmare > pred_paradise * 1.5:
            print("âœ… SONUÃ‡: Model piyasa fizik kurallarÄ±nÄ± kavramÄ±ÅŸ. KÄ±tlÄ±kta fiyatÄ± uÃ§uruyor.")
        else:
            print("âš ï¸ SONUÃ‡: Model ekstrem durumlara yeterince sert tepki vermiyor.")
    except Exception as e:
        print(f"âš ï¸ Stres testi sÄ±rasÄ±nda hata: {e}")

    # -------------------------------------------------------------------------
    # TEST 4: CONFIDENCE INTERVALS (GÃœVEN ARALIÄI)
    # -------------------------------------------------------------------------
    print("\nğŸ§ª TEST 4: GÃœVEN ARALIÄI (Son 1 Hafta)")
    print("-" * 40)

    # Son 1 haftayÄ± bul
    last_date = date_series.max()
    first_date_viz = last_date - pd.Timedelta(days=7)

    mask_viz = (date_series >= first_date_viz) & (date_series <= last_date)

    if mask_viz.sum() > 0:
        X_viz = X_full.loc[mask_viz]
        y_viz = y_full.loc[mask_viz]
        dates_viz = date_series.loc[mask_viz]

        preds_viz = model.predict(X_viz)
        preds_viz = np.maximum(preds_viz, 0)

        # Modelin genel hatasÄ±nÄ± (RMSE) baz alarak bant Ã§iziyoruz
        # (Burada manuel 452 yerine dinamik hesaplama yapabiliriz ama orijinal koda sadÄ±k kaldÄ±m)
        rmse_viz = np.sqrt(mean_squared_error(y_viz, preds_viz))
        confidence_interval = 1.96 * rmse_viz  # %95 GÃ¼ven AralÄ±ÄŸÄ±

        lower_bound = preds_viz - confidence_interval
        upper_bound = preds_viz + confidence_interval
        lower_bound = np.maximum(lower_bound, 0)

        plt.figure(figsize=(15, 7))
        plt.plot(dates_viz, y_viz, label='GerÃ§ekleÅŸen', color='black', linewidth=2)
        plt.plot(dates_viz, preds_viz, label='Tahmin', color='blue', linestyle='--')

        # GÃ¼ven aralÄ±ÄŸÄ±nÄ± boya
        plt.fill_between(dates_viz, lower_bound, upper_bound, color='blue', alpha=0.2,
                         label=f'%95 GÃ¼ven AralÄ±ÄŸÄ± (+/- {confidence_interval:.0f} TL)')

        plt.title('Model GÃ¼venilirlik BandÄ± (Son 1 Hafta)', fontsize=14)
        plt.ylabel('PTF (TL/MWh)')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.show()

        print("âœ… Grafik Ã§izildi. Mavi alan, modelin gÃ¼venli limanÄ±dÄ±r.")
    else:
        print("âš ï¸ GÃ¶rselleÅŸtirme iÃ§in yeterli veri yok.")

    print("\nâœ… GÃ¼venilirlik testleri tamamlandÄ±.")

# =============================================================================
# KULLANIM
# =============================================================================
# 1. PARÃ‡ALARI BÄ°RLEÅTÄ°R (X ve y)
# -----------------------------------------------------------------------------
# EÄŸitim ve Test setlerini alt alta ekleyerek bÃ¼tÃ¼n veriyi elde ediyoruz.
X_full = pd.concat([X_train, X_test])
y_full = pd.concat([y_train, y_test])

# 2. TARÄ°HLERÄ° EÅLEÅTÄ°R (KRÄ°TÄ°K DÃœZELTME ğŸ› ï¸)
# -----------------------------------------------------------------------------
# Hata burada Ã§Ä±kÄ±yordu. 'dates_train' falan aramak yerine,
# Elimizdeki 'y_full'un indeksini kullanarak ana tarih listesinden (all_dates)
# doÄŸru tarihleri Ã§ekip alÄ±yoruz. En gÃ¼venli yÃ¶ntem budur.

# all_dates deÄŸiÅŸkeni AdÄ±m 6'dan (run_model_training) gelmiÅŸ olmalÄ±.
# EÄŸer adÄ± farklÄ±ysa (Ã¶rn: dates) burayÄ± ona gÃ¶re deÄŸiÅŸtir.
full_dates_aligned = all_dates.loc[y_full.index]

# 3. TAHMÄ°N ÃœRET
# -----------------------------------------------------------------------------
# Residual analizi iÃ§in test seti tahminlerini hazÄ±rlayalÄ±m.
y_pred_final = best_model.predict(X_test)
y_pred_final = np.maximum(y_pred_final, 0) # Negatif fiyat korumasÄ±

# 4. FONKSÄ°YONLARI Ã‡ALIÅTIR
# -----------------------------------------------------------------------------
print(f"\nğŸš€ AdÄ±m 9 BaÅŸlatÄ±lÄ±yor...")
print(f"   Analiz edilecek toplam veri sayÄ±sÄ±: {len(X_full)} satÄ±r")

# A) GÃ¼venilirlik Testi (TÃ¼m yÄ±l iÃ§in)
run_reliability_tests(best_model, X_full, y_full, full_dates_aligned)

# B) Residual (Hata) Analizi (Sadece Test ayÄ± iÃ§in)
residuals = run_residual_analysis(y_test, y_pred_final)
#////////////////////////////////////////////////////////////////////////////////////
